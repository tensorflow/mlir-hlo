// RUN: stablehlo-opt -inline %s | stablehlo-translate --interpret
// RUN: stablehlo-translate --serialize --target=current %s | stablehlo-translate --deserialize | stablehlo-opt > %t.0
// RUN: stablehlo-opt %s > %t.1
// RUN: diff %t.0 %t.1

module @jit_main attributes {mhlo.num_partitions = 1 : i32, mhlo.num_replicas = 1 : i32} {
  func.func public @main() -> (tensor<8x9xf32> {jax.result_info = "", mhlo.layout_mode = "default"}) {
    %0 = call @inputs() : () -> tensor<8x9xf32>
    %1 = call @expected() : () -> tensor<8x9xf32>
    %2 = call @cumsum(%0) : (tensor<8x9xf32>) -> tensor<8x9xf32>
    stablehlo.custom_call @check.expect_close(%2, %1) {has_side_effect = true} : (tensor<8x9xf32>, tensor<8x9xf32>) -> ()
    return %2 : tensor<8x9xf32>
  }
  func.func private @inputs() -> (tensor<8x9xf32> {mhlo.layout_mode = "default"}) {
    %cst = stablehlo.constant dense<[[2.16102052, 4.5972209, -0.605086624, -2.67837787, -0.432551891, -0.492433369, 2.71063924, -1.63862252, 2.46858406], [-1.90158689, -2.66357183, 3.20973015, -3.44255519, -0.434785724, 2.72661686, -0.448676556, 0.00468171714, -1.74962008], [-6.6869483, -2.36254311, -0.268346637, -1.65326738, 0.610868216, 0.941075682, 5.77247143, -2.94513083, 0.679063737], [-4.5778203, -1.4385494, 0.00158312498, -7.45802689, -0.840607762, -0.436943114, -3.04456496, 0.200867087, 2.18134856], [0.440132767, -1.74513936, 0.836728096, 3.65207505, -0.253780961, -5.14488506, 3.1484561, -5.60917664, 4.07253218], [-0.219530672, 2.78076982, -3.3338871, 3.02256274, 1.07516503, -0.121814221, 1.9156096, -0.148681492, -4.5330658], [-0.869096041, -1.52695727, -1.55918503, 0.443289489, 1.00706577, 1.25517082, 0.659457981, 0.100887813, 1.69707549], [0.075337626, -1.44793224, -0.498889834, 0.475584716, 2.04891396, 1.7912066, -4.95147228, 0.243149757, 1.89234078]]> : tensor<8x9xf32>
    return %cst : tensor<8x9xf32>
  }
  func.func private @expected() -> (tensor<8x9xf32> {mhlo.layout_mode = "default"}) {
    %cst = stablehlo.constant dense<[[2.16102052, 4.5972209, -0.605086624, -2.67837787, -0.432551891, -0.492433369, 2.71063924, -1.63862252, 2.46858406], [0.259433627, 1.93364906, 2.60464358, -6.12093306, -0.867337584, 2.23418355, 2.26196265, -1.63394082, 7.189640e-01], [-6.42751455, -0.428894043, 2.33629704, -7.77420044, -0.256469369, 3.17525911, 8.03443431, -4.57907152, 1.39802766], [-11.0053349, -1.86744344, 2.33788013, -15.2322273, -1.09707713, 2.73831606, 4.98986912, -4.37820435, 3.57937622], [-10.5652018, -3.61258268, 3.17460823, -11.5801525, -1.35085809, -2.406569, 8.13832474, -9.98738098, 7.6519084], [-10.7847328, -0.831812858, -0.15927887, -8.55758953, -0.275693059, -2.52838326, 10.0539341, -10.1360626, 3.1188426], [-11.6538286, -2.35877013, -1.7184639, -8.114300e+00, 0.731372714, -1.27321243, 10.7133923, -10.0351744, 4.81591797], [-11.5784912, -3.80670238, -2.21735382, -7.63871527, 2.78028679, 0.517994165, 5.761920e+00, -9.79202461, 6.70825862]]> : tensor<8x9xf32>
    return %cst : tensor<8x9xf32>
  }
  func.func private @cumsum(%arg0: tensor<8x9xf32>) -> tensor<8x9xf32> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f32>) -> tensor<f32>
    %1 = "stablehlo.reduce_window"(%arg0, %0) <{padding = dense<[[7, 0], [0, 0]]> : tensor<2x2xi64>, window_dimensions = array<i64: 8, 1>}> ({
    ^bb0(%arg1: tensor<f32>, %arg2: tensor<f32>):
      %2 = stablehlo.add %arg1, %arg2 : tensor<f32>
      stablehlo.return %2 : tensor<f32>
    }) : (tensor<8x9xf32>, tensor<f32>) -> tensor<8x9xf32>
    return %1 : tensor<8x9xf32>
  }
}
