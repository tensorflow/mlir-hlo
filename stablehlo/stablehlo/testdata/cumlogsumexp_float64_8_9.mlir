// RUN: stablehlo-opt -inline %s | stablehlo-translate --interpret
// RUN: stablehlo-translate --serialize --target=current %s | stablehlo-translate --deserialize | stablehlo-opt > %t.0
// RUN: stablehlo-opt %s > %t.1
// RUN: diff %t.0 %t.1

module @jit_main attributes {mhlo.num_partitions = 1 : i32, mhlo.num_replicas = 1 : i32} {
  func.func public @main() -> (tensor<8x9xf64> {jax.result_info = "", mhlo.layout_mode = "default"}) {
    %0 = call @inputs() : () -> tensor<8x9xf64>
    %1 = call @expected() : () -> tensor<8x9xf64>
    %2 = call @cumlogsumexp(%0) : (tensor<8x9xf64>) -> tensor<8x9xf64>
    stablehlo.custom_call @check.expect_close(%2, %1) {has_side_effect = true} : (tensor<8x9xf64>, tensor<8x9xf64>) -> ()
    return %2 : tensor<8x9xf64>
  }
  func.func private @inputs() -> (tensor<8x9xf64> {mhlo.layout_mode = "default"}) {
    %cst = stablehlo.constant dense<[[-3.2769925575352157, 3.3903430102143801, -0.93427112822958236, -1.1841607582194449, -0.02564472289212405, 3.9913898528339726, 1.8172573017510576, 1.8984646775613223, -2.0139874360121341], [1.9247204428386961, 4.5502843302440947, -1.2676268625626652, -1.6180130145806828, 1.5464588354395294, -4.2696916772755182, -0.83714232666535204, 6.7783727877698752, -4.4874388555798905], [-1.6649081102148022, -1.3400305674665747, 2.0787402791124583, -7.8259606954374572, -1.4058051548100781, 5.5047074682669281, -4.3579671009897911, 5.0962007072191007, 5.5974755943289827], [3.3964354570634949, 1.7843605941928453, -1.0084338333779284, 0.64473073587792862, 1.4238096153408915, 1.5942364903972015, 4.5069116270693312, -0.81808489632603187, -1.6258910726860607], [2.8588889389863708, -3.3318555863565864, -2.5034616559442666, -5.2738461306820881, -1.1316646813766236, 2.2332127224561855, 0.58005326767268328, -1.3346892934773349, -3.3872019978392154], [1.5505741925071896, 0.018851226564393614, -7.0191813880086027, -1.0851092570629706, 3.4100380222803457, -2.5794575907900734, 1.2395726331909023, 2.245620085816828, -5.4470901070046986], [-0.86213775194509934, 1.6377889822146667, -0.62375408568788404, -0.80923917786615406, 5.2315160905910592, 0.2890600029205489, -2.5089132984387144, -6.1164095570381454, -1.6608806530748192], [-7.9300336047240813, 4.0964097774536032, 0.64721917348666713, 0.6106483268780819, 3.5656671602397028, 5.6371333848675205, 2.0613275285526305, 4.2621096005107191, -0.25520778286613266]]> : tensor<8x9xf64>
    return %cst : tensor<8x9xf64>
  }
  func.func private @expected() -> (tensor<8x9xf64> {mhlo.layout_mode = "default"}) {
    %cst = stablehlo.constant dense<[[-3.2769925575352157, 3.3903430102143801, -0.93427112822958236, -1.1841607582194449, -0.02564472289212405, 3.9913898528339726, 1.8172573017510576, 1.8984646775613223, -2.0139874360121341], [1.9302124567170231, 4.8229831447987745, -0.39397490432385951, -0.68459347997734699, 1.7351003849018223, 3.9916481988547234, 1.8852346440742815, 6.7859417826678303, -1.9330588829217368], [1.9572996366512829, 4.8250868276363237, 2.1597260869431278, -0.68380212420779363, 1.7774351111625066, 5.7037510850970792, 1.8871763802498769, 6.9553193486450491, 5.5980119019492864], [3.609231735764078, 4.8717797110100927, 2.2009457230564045, 0.87969658460753852, 2.3093201437260222, 5.7200335443362587, 4.5772043175828321, 6.9557400385357822, 5.5987405881721894], [3.9959927781726914, 4.8720533305080655, 2.2099602488306402, 0.88182026482578968, 2.3408509059730451, 5.750172754981012, 4.5954055590606186, 6.9559909137812861, 5.5988657372184125], [4.0791290099762998, 4.8798263921981517, 2.2100583814531203, 1.0127482708918205, 3.7051579577268061, 5.7504139870938307, 4.6296913320790694, 6.9649520812946131, 5.5988816886206196], [4.0862491425023029, 4.9181661245348263, 2.2671835200924337, 1.1626362091391804, 5.4281724934165503, 5.7546527910523082, 4.630484876190315, 6.9649541650002771, 5.5995847165934602], [4.0862551874618269, 5.2825722534951325, 2.4477583480515301, 1.6174018535618777, 5.5725179213889042, 6.390765627357661, 4.7042928641396289, 7.0298188335385339, 5.6024467473364163]]> : tensor<8x9xf64>
    return %cst : tensor<8x9xf64>
  }
  func.func private @cumlogsumexp(%arg0: tensor<8x9xf64>) -> tensor<8x9xf64> {
    %cst = stablehlo.constant dense<0xFFF0000000000000> : tensor<f64>
    %0 = "stablehlo.reduce_window"(%arg0, %cst) <{padding = dense<[[7, 0], [0, 0]]> : tensor<2x2xi64>, window_dimensions = array<i64: 8, 1>}> ({
    ^bb0(%arg1: tensor<f64>, %arg2: tensor<f64>):
      %1 = func.call @logaddexp(%arg1, %arg2) : (tensor<f64>, tensor<f64>) -> tensor<f64>
      stablehlo.return %1 : tensor<f64>
    }) : (tensor<8x9xf64>, tensor<f64>) -> tensor<8x9xf64>
    return %0 : tensor<8x9xf64>
  }
  func.func private @logaddexp(%arg0: tensor<f64> {mhlo.layout_mode = "default"}, %arg1: tensor<f64> {mhlo.layout_mode = "default"}) -> (tensor<f64> {mhlo.layout_mode = "default"}) {
    %0 = stablehlo.maximum %arg0, %arg1 : tensor<f64>
    %1 = stablehlo.subtract %arg0, %arg1 : tensor<f64>
    %2 = stablehlo.compare  NE, %1, %1,  FLOAT : (tensor<f64>, tensor<f64>) -> tensor<i1>
    %3 = stablehlo.add %arg0, %arg1 : tensor<f64>
    %4 = stablehlo.abs %1 : tensor<f64>
    %5 = stablehlo.negate %4 : tensor<f64>
    %6 = stablehlo.exponential %5 : tensor<f64>
    %7 = stablehlo.log_plus_one %6 : tensor<f64>
    %8 = stablehlo.add %0, %7 : tensor<f64>
    %9 = stablehlo.select %2, %3, %8 : tensor<i1>, tensor<f64>
    return %9 : tensor<f64>
  }
}
